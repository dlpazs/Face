{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arcface DeepInsight.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paruliansaragi/Face/blob/master/Arcface_DeepInsight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOtlrAuN-0MC",
        "colab_type": "text"
      },
      "source": [
        "# Install Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lp81MeZn73k",
        "colab_type": "code",
        "outputId": "3f985ac0-0b69-4c7d-c6cd-690670abdde1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/deepinsight/insightface.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'insightface'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 2634 (delta 2), reused 2 (delta 0), pack-reused 2625\u001b[K\n",
            "Receiving objects: 100% (2634/2634), 18.62 MiB | 7.76 MiB/s, done.\n",
            "Resolving deltas: 100% (1635/1635), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kduK5HSWoWkx",
        "colab_type": "code",
        "outputId": "8bd255ff-6320-417b-9ed2-af8c39604a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFc8MJI0odaj",
        "colab_type": "code",
        "outputId": "224e4d21-880b-4963-ad7e-183328cc2d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "!pip install mxnet-cu100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet-cu100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/91/b5c2692297aa5b8c383e0da18f9208fc6d5519d981c03266abfbde897c41/mxnet_cu100-1.4.1-py2.py3-none-manylinux1_x86_64.whl (488.3MB)\n",
            "\u001b[K     |████████████████████████████████| 488.3MB 33kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Collecting numpy<1.15.0,>=1.8.2 (from mxnet-cu100)\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/e5/c4/395ebb218053ba44d64935b3729bc88241ec279915e72100c5979db10945/numpy-1.14.6-cp36-cp36m-manylinux1_x86_64.whl\u001b[0m\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c4/395ebb218053ba44d64935b3729bc88241ec279915e72100c5979db10945/numpy-1.14.6-cp36-cp36m-manylinux1_x86_64.whl (13.8MB)\n",
            "\u001b[K     |████████████████████████████████| 13.8MB 1.4MB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1 (from mxnet-cu100)\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.6.16)\n",
            "\u001b[31mERROR: spacy 2.1.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.54 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, graphviz, mxnet-cu100\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu100-1.4.1 numpy-1.14.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdGWupggoi0d",
        "colab_type": "code",
        "outputId": "5443518e-8571-4278-9e0c-fe6b8c37764c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "%cd ./insightface/models\n",
        "!unzip ../../model-r100-arcface-ms1m-refine-v2.zip\n",
        "%cd ../../"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/insightface/models\n",
            "Archive:  ../../model-r100-arcface-ms1m-refine-v2.zip\n",
            "warning [../../model-r100-arcface-ms1m-refine-v2.zip]:  240349162 extra bytes at beginning or within zipfile\n",
            "  (attempting to process anyway)\n",
            "file #1:  bad zipfile offset (local header sig):  240349162\n",
            "  (attempting to re-compensate)\n",
            "   creating: model-r100-ii/\n",
            "  inflating: model-r100-ii/log       \n",
            "  inflating: model-r100-ii/model-0000.params  \n",
            "  error:  invalid compressed data to inflate\n",
            "file #4:  bad zipfile offset (local header sig):  243481016\n",
            "  (attempting to re-compensate)\n",
            "  inflating: model-r100-ii/model-symbol.json  \n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeolmtGRtvgd",
        "colab_type": "code",
        "outputId": "9fca58df-fde6-4a2b-ef2e-d8b2eada721d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/wpx6tqjf0y5mf6r/faces_ms1m-refine-v2_112x112.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-03 07:54:16--  https://www.dropbox.com/s/wpx6tqjf0y5mf6r/faces_ms1m-refine-v2_112x112.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/wpx6tqjf0y5mf6r/faces_ms1m-refine-v2_112x112.zip [following]\n",
            "--2019-07-03 07:54:17--  https://www.dropbox.com/s/raw/wpx6tqjf0y5mf6r/faces_ms1m-refine-v2_112x112.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc12e846389d5cbf9c2d696c11c4.dl.dropboxusercontent.com/cd/0/inline/Aj_nul4NHrRw_Sr9d5gZcx-CE7ohcLlK6XzzZa4qB9BPu4hBsfnvJwzADBh7ZFWuDGdX3FEtco3q9eYNHDabPW05UBQxjbTYIosXSFJiiJnX2Q/file# [following]\n",
            "--2019-07-03 07:54:17--  https://uc12e846389d5cbf9c2d696c11c4.dl.dropboxusercontent.com/cd/0/inline/Aj_nul4NHrRw_Sr9d5gZcx-CE7ohcLlK6XzzZa4qB9BPu4hBsfnvJwzADBh7ZFWuDGdX3FEtco3q9eYNHDabPW05UBQxjbTYIosXSFJiiJnX2Q/file\n",
            "Resolving uc12e846389d5cbf9c2d696c11c4.dl.dropboxusercontent.com (uc12e846389d5cbf9c2d696c11c4.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
            "Connecting to uc12e846389d5cbf9c2d696c11c4.dl.dropboxusercontent.com (uc12e846389d5cbf9c2d696c11c4.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/Aj8b3NMvfv39gEUjykiHA1EChUUKV7bvbaOX6xr8LF--Z09F6HmNoRA9G7W9t4jDNZaU_7zrHHPxuJ7wZUoA-yWLqEITKwloZKNtEIhofpptmZM-UGNv_qKXOq8zBhy-3cZObame6NcGXNH37yX58wjkCI6OwIGjpIDmSKcv4z2RE94comsdGodFoduAJxe8VHU001OkaPIYAzTN1g7i45NSBuwz5UQeHdaA9jf2I7_q0uCfi3M4CAoX7VlHetwlq-0Ut7a0tgWz6iDPdt_Uksk3kM_t1F0LhjG4OkV0Hd1DucQjBHHYTp-FEFkn-fkFJHsPleOEB7diJMtCKnvjehY9/file [following]\n",
            "--2019-07-03 07:54:18--  https://uc12e846389d5cbf9c2d696c11c4.dl.dropboxusercontent.com/cd/0/inline2/Aj8b3NMvfv39gEUjykiHA1EChUUKV7bvbaOX6xr8LF--Z09F6HmNoRA9G7W9t4jDNZaU_7zrHHPxuJ7wZUoA-yWLqEITKwloZKNtEIhofpptmZM-UGNv_qKXOq8zBhy-3cZObame6NcGXNH37yX58wjkCI6OwIGjpIDmSKcv4z2RE94comsdGodFoduAJxe8VHU001OkaPIYAzTN1g7i45NSBuwz5UQeHdaA9jf2I7_q0uCfi3M4CAoX7VlHetwlq-0Ut7a0tgWz6iDPdt_Uksk3kM_t1F0LhjG4OkV0Hd1DucQjBHHYTp-FEFkn-fkFJHsPleOEB7diJMtCKnvjehY9/file\n",
            "Reusing existing connection to uc12e846389d5cbf9c2d696c11c4.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13247758075 (12G) [application/zip]\n",
            "Saving to: ‘faces_ms1m-refine-v2_112x112.zip’\n",
            "\n",
            "faces_ms1m-refine-v 100%[===================>]  12.34G  36.5MB/s    in 4m 41s  \n",
            "\n",
            "2019-07-03 07:58:59 (45.0 MB/s) - ‘faces_ms1m-refine-v2_112x112.zip’ saved [13247758075/13247758075]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAQPob8VzHj9",
        "colab_type": "code",
        "outputId": "5dffbc84-9a78-4077-90c0-8a1ebc1b11da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!unzip ./faces_ms1m-refine-v2_112x112.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./faces_ms1m-refine-v2_112x112.zip\n",
            "   creating: faces_emore/\n",
            "  inflating: faces_emore/property    \n",
            "  inflating: faces_emore/vgg2_fp.bin  \n",
            "  inflating: faces_emore/calfw.bin   \n",
            "  inflating: faces_emore/train.rec   \n",
            "  inflating: faces_emore/cplfw.bin   \n",
            "  inflating: faces_emore/agedb_30.bin  \n",
            "  inflating: faces_emore/train.idx   \n",
            "  inflating: faces_emore/cfp_fp.bin  \n",
            "  inflating: faces_emore/cfp_ff.bin  \n",
            "  inflating: faces_emore/lfw.bin     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywYZ3mh62D-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK_oCSIJ2SmV",
        "colab_type": "code",
        "outputId": "ee03b569-97dc-488d-b5e9-100e0a536588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzSArZg92TOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv ./model-r100-arcface-ms1m-refine-v2.zip \"./drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fPRF-SM3PsQ",
        "colab_type": "code",
        "outputId": "57c00d4c-cc00-49b6-d785-a3987c547012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!unzip \"./drive/My Drive/model-r100-arcface-ms1m-refine-v2.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./drive/My Drive/model-r100-arcface-ms1m-refine-v2.zip\n",
            "   creating: model-r100-ii/\n",
            "  inflating: model-r100-ii/log       \n",
            "  inflating: model-r100-ii/model-0000.params  \n",
            "  inflating: model-r100-ii/model-symbol.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXGmcVpnAUwZ",
        "colab_type": "code",
        "outputId": "f4ff77fb-b9d6-4dab-d9f1-c8da4d290411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd insightface"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/insightface\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qabC9vi3A1Xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv ../faces_emore ./datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_PV5hE1A-rJ",
        "colab_type": "code",
        "outputId": "480c650a-b5c1-4f84-e2ca-313951e5b4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd src/eval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/insightface/src/eval\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CC-LXqOBsWO",
        "colab_type": "code",
        "outputId": "32e587f4-99ee-49a2-d262-a5735e62b9e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!ls ../../datasets/faces_emore\n",
        "!ls ../../models/model-r100-ii/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log  model-0000.params\tmodel-symbol.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDaEWEKIHVi8",
        "colab_type": "code",
        "outputId": "f623d796-cbd0-4437-ade7-43946be60f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd ../../models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/insightface/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtWgQMS_HZJM",
        "colab_type": "code",
        "outputId": "0078e3c7-b83b-4c9d-9503-6e147b13001f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!unzip \"../../drive/My Drive/model-r50-arcface-ms1m-refine-v1.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ../../drive/My Drive/model-r50-arcface-ms1m-refine-v1.zip\n",
            "   creating: model-r50-am-lfw/\n",
            "  inflating: model-r50-am-lfw/log    \n",
            "  inflating: model-r50-am-lfw/model-0000.params  \n",
            "  inflating: model-r50-am-lfw/model-symbol.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwF1iKVZHifU",
        "colab_type": "code",
        "outputId": "88809f52-3f1f-483b-c400-d40a377d2764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd ../src/eval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/insightface/src/eval\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59kjq4CPINef",
        "colab_type": "code",
        "outputId": "014cd8c1-c40d-4a39-874b-125a40319307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls ../../datasets/faces_emore/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "agedb_30.bin  cfp_ff.bin  cplfw.bin  property\ttrain.rec\n",
            "calfw.bin     cfp_fp.bin  lfw.bin    train.idx\tvgg2_fp.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xySOoVvhBlYz",
        "colab_type": "code",
        "outputId": "8ae870c6-3b47-4a89-bd4a-3cbcde8cc33d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "!python verification.py --data-dir ../../datasets/faces_emore/ --model ../../models/model-r50-am-lfw/model,0 --batch-size 1 --nfolds 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image_size [112, 112]\n",
            "model number 1\n",
            "loading ../../models/model-r50-am-lfw/model 0\n",
            "[09:18:22] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.12.1. Attempting to upgrade...\n",
            "[09:18:22] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\n",
            "model loading time 2.298717\n",
            "loading..  lfw\n",
            "Traceback (most recent call last):\n",
            "  File \"verification.py\", line 569, in <module>\n",
            "    data_set = load_bin(path, image_size)\n",
            "  File \"verification.py\", line 185, in load_bin\n",
            "    bins, issame_list = pickle.load(open(path, 'rb'))\n",
            "UnicodeDecodeError: 'ascii' codec can't decode byte 0xff in position 0: ordinal not in range(128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJb4Arcd-eg-",
        "colab_type": "text"
      },
      "source": [
        "# Begin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrVyKbQEOslT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title imports \n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import sys\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy import interpolate\n",
        "import sklearn\n",
        "import cv2\n",
        "import math\n",
        "import datetime\n",
        "import pickle\n",
        "from sklearn.decomposition import PCA\n",
        "import mxnet as mx\n",
        "from mxnet import ndarray as nd\n",
        "#sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'common'))\n",
        "sys.path.append('../common')\n",
        "import face_image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnB715_POl06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title calculate_roc \n",
        "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10, pca = 0):\n",
        "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
        "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
        "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
        "    nrof_thresholds = len(thresholds)\n",
        "    k_fold = LFold(n_splits=nrof_folds, shuffle=False)\n",
        "    \n",
        "    tprs = np.zeros((nrof_folds,nrof_thresholds))\n",
        "    fprs = np.zeros((nrof_folds,nrof_thresholds))\n",
        "    accuracy = np.zeros((nrof_folds))\n",
        "    indices = np.arange(nrof_pairs)\n",
        "    #print('pca', pca)\n",
        "    \n",
        "    if pca==0:\n",
        "      diff = np.subtract(embeddings1, embeddings2)\n",
        "      dist = np.sum(np.square(diff),1)\n",
        "    \n",
        "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
        "        #print('train_set', train_set)\n",
        "        #print('test_set', test_set)\n",
        "        if pca>0:\n",
        "          print('doing pca on', fold_idx)\n",
        "          embed1_train = embeddings1[train_set]\n",
        "          embed2_train = embeddings2[train_set]\n",
        "          _embed_train = np.concatenate( (embed1_train, embed2_train), axis=0 )\n",
        "          #print(_embed_train.shape)\n",
        "          pca_model = PCA(n_components=pca)\n",
        "          pca_model.fit(_embed_train)\n",
        "          embed1 = pca_model.transform(embeddings1)\n",
        "          embed2 = pca_model.transform(embeddings2)\n",
        "          embed1 = sklearn.preprocessing.normalize(embed1)\n",
        "          embed2 = sklearn.preprocessing.normalize(embed2)\n",
        "          #print(embed1.shape, embed2.shape)\n",
        "          diff = np.subtract(embed1, embed2)\n",
        "          dist = np.sum(np.square(diff),1)\n",
        "        \n",
        "        # Find the best threshold for the fold\n",
        "        \n",
        "        #My changes\n",
        "        #tpr, fpr = np.zeros((nrof_thresholds)), np.zeros((nrof_thresholds))\n",
        "        \n",
        "        acc_train = np.zeros((nrof_thresholds))\n",
        "        for threshold_idx, threshold in enumerate(thresholds):\n",
        "            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
        "            #tpr, fpr, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
        "        best_threshold_index = np.argmax(acc_train)\n",
        "        #print('threshold', thresholds[best_threshold_index])\n",
        "        for threshold_idx, threshold in enumerate(thresholds):\n",
        "            tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
        "        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
        "          \n",
        "    tpr = np.mean(tprs,0)\n",
        "    fpr = np.mean(fprs,0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return tpr, fpr, accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjvq2BYEOu-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title LFold\n",
        "class LFold:\n",
        "  def __init__(self, n_splits = 2, shuffle = False):\n",
        "    self.n_splits = n_splits\n",
        "    if self.n_splits>1:\n",
        "      self.k_fold = KFold(n_splits = n_splits, shuffle = shuffle)\n",
        "\n",
        "  def split(self, indices):\n",
        "    if self.n_splits>1:\n",
        "      return self.k_fold.split(indices)\n",
        "    else:\n",
        "      return [(indices, indices)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISn0aDR-Qkfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Evaluate & load bin\n",
        "def evaluate(embeddings, actual_issame, nrof_folds=10, pca = 0):\n",
        "    # Calculate evaluation metrics\n",
        "    thresholds = np.arange(0, 4, 0.01)\n",
        "    embeddings1 = embeddings[0::2]\n",
        "    embeddings2 = embeddings[1::2]\n",
        "    tpr, fpr, accuracy = calculate_roc(thresholds, embeddings1, embeddings2,\n",
        "        np.asarray(actual_issame), nrof_folds=nrof_folds, pca = pca)\n",
        "    thresholds = np.arange(0, 4, 0.001)\n",
        "    val, val_std, far = calculate_val(thresholds, embeddings1, embeddings2,\n",
        "        np.asarray(actual_issame), 1e-3, nrof_folds=nrof_folds)\n",
        "    return tpr, fpr, accuracy, val, val_std, far\n",
        "\n",
        "def load_bin(path, image_size):\n",
        "  bins, issame_list = pickle.load(open(path, 'rb'), encoding='bytes')\n",
        "  data_list = []\n",
        "  for flip in [0,1]:\n",
        "    data = nd.empty((len(issame_list)*2, 3, image_size[0], image_size[1]))\n",
        "    data_list.append(data)\n",
        "  for i in range(len(issame_list)*2):\n",
        "    _bin = bins[i]\n",
        "    img = mx.image.imdecode(_bin)\n",
        "    if img.shape[1]!=image_size[0]:\n",
        "      img = mx.image.resize_short(img, image_size[0])\n",
        "    img = nd.transpose(img, axes=(2, 0, 1))\n",
        "    for flip in [0,1]:\n",
        "      if flip==1:\n",
        "        img = mx.ndarray.flip(data=img, axis=2)\n",
        "      data_list[flip][i][:] = img\n",
        "    if i%1000==0:\n",
        "      print('loading bin', i)\n",
        "  print(data_list[0].shape)\n",
        "  return (data_list, issame_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjrPUsSoj11P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Counter():\n",
        "  def __init__(self):\n",
        "    self.thresholds = np.arange(0, 4, 0.01)\n",
        "    self.nrof_folds = 10\n",
        "    self.nrof_thresholds = len(self.thresholds)\n",
        "    self.tpc = np.zeros((self.nrof_folds, self.nrof_thresholds))\n",
        "    self.fpc = np.zeros((self.nrof_folds,self.nrof_thresholds))\n",
        "    self.tnc = np.zeros((self.nrof_folds,self.nrof_thresholds))\n",
        "    self.fnc = np.zeros((self.nrof_folds,self.nrof_thresholds))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52wu-CRhkYOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ts_fs_counter = Counter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rYKtAb_oA7v",
        "colab_type": "code",
        "outputId": "bfd13942-352d-4f26-dc2b-e03b77cf8456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "ts_fs_counter.tnc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8JWNn5MCHa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title calculate accuracy/val/val_far\n",
        "def calculate_accuracy(threshold, dist, actual_issame):\n",
        "    predict_issame = np.less(dist, threshold)\n",
        "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n",
        "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
        "    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\n",
        "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n",
        "    #\n",
        "    ts_fs_counter.tpc = tp\n",
        "    ts_fs_counter.fpc = fp\n",
        "    ts_fs_counter.tnc = tn\n",
        "    ts_fs_counter.fnc = fn\n",
        "    #\n",
        "  \n",
        "    tpr = 0 if (tp+fn==0) else float(tp) / float(tp+fn)\n",
        "    fpr = 0 if (fp+tn==0) else float(fp) / float(fp+tn)\n",
        "    acc = float(tp+tn)/dist.size\n",
        "    return tpr, fpr, acc, tp, fp, tn, fn\n",
        "    #return tpr, fpr, acc\n",
        "\n",
        "\n",
        "  \n",
        "def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10):\n",
        "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
        "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
        "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
        "    nrof_thresholds = len(thresholds)\n",
        "    k_fold = LFold(n_splits=nrof_folds, shuffle=False)\n",
        "    \n",
        "    val = np.zeros(nrof_folds)\n",
        "    far = np.zeros(nrof_folds)\n",
        "    \n",
        "    diff = np.subtract(embeddings1, embeddings2)\n",
        "    dist = np.sum(np.square(diff),1)\n",
        "    indices = np.arange(nrof_pairs)\n",
        "    \n",
        "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
        "      \n",
        "        # Find the threshold that gives FAR = far_target\n",
        "        far_train = np.zeros(nrof_thresholds)\n",
        "        for threshold_idx, threshold in enumerate(thresholds):\n",
        "            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set], actual_issame[train_set])\n",
        "        if np.max(far_train)>=far_target:\n",
        "            f = interpolate.interp1d(far_train, thresholds, kind='slinear')\n",
        "            threshold = f(far_target)\n",
        "        else:\n",
        "            threshold = 0.0\n",
        "    \n",
        "        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set], actual_issame[test_set])\n",
        "  \n",
        "    val_mean = np.mean(val)\n",
        "    far_mean = np.mean(far)\n",
        "    val_std = np.std(val)\n",
        "    return val_mean, val_std, far_mean\n",
        "\n",
        "\n",
        "def calculate_val_far(threshold, dist, actual_issame):\n",
        "    predict_issame = np.less(dist, threshold)\n",
        "    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n",
        "    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
        "    n_same = np.sum(actual_issame)\n",
        "    n_diff = np.sum(np.logical_not(actual_issame))\n",
        "    #print(true_accept, false_accept)\n",
        "    #print(n_same, n_diff)\n",
        "    val = float(true_accept) / float(n_same)\n",
        "    far = float(false_accept) / float(n_diff)\n",
        "    return val, far\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enpmBB5Flc1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title modified test badcase { form-width: \"45px\" }\n",
        "\n",
        "def mod_test_badcase(data_set, mx_model, batch_size, name='', data_extra = None, label_shape = None):\n",
        "  print('testing verification badcase..')\n",
        "  data_list = data_set[0]\n",
        "  issame_list = data_set[1]\n",
        "  model = mx_model\n",
        "  embeddings_list = []\n",
        "  if data_extra is not None:\n",
        "    _data_extra = nd.array(data_extra)\n",
        "  time_consumed = 0.0\n",
        "  if label_shape is None:\n",
        "    _label = nd.ones( (batch_size,) )\n",
        "  else:\n",
        "    _label = nd.ones( label_shape )\n",
        "  for i in range( len(data_list) ):\n",
        "    data = data_list[i]\n",
        "    embeddings = None\n",
        "    ba = 0\n",
        "    while ba<data.shape[0]:\n",
        "      bb = min(ba+batch_size, data.shape[0])\n",
        "      count = bb-ba\n",
        "      _data = nd.slice_axis(data, axis=0, begin=bb-batch_size, end=bb)\n",
        "      #print(_data.shape, _label.shape)\n",
        "      time0 = datetime.datetime.now()\n",
        "      if data_extra is None:\n",
        "        db = mx.io.DataBatch(data=(_data,), label=(_label,))\n",
        "      else:\n",
        "        db = mx.io.DataBatch(data=(_data,_data_extra), label=(_label,))\n",
        "      model.forward(db, is_train=False)\n",
        "      net_out = model.get_outputs()\n",
        "      _embeddings = net_out[0].asnumpy()\n",
        "      time_now = datetime.datetime.now()\n",
        "      diff = time_now - time0\n",
        "      time_consumed+=diff.total_seconds()\n",
        "      if embeddings is None:\n",
        "        embeddings = np.zeros( (data.shape[0], _embeddings.shape[1]) )\n",
        "      embeddings[ba:bb,:] = _embeddings[(batch_size-count):,:]\n",
        "      ba = bb\n",
        "    embeddings_list.append(embeddings)\n",
        "  embeddings = embeddings_list[0] + embeddings_list[1]\n",
        "  embeddings = sklearn.preprocessing.normalize(embeddings)\n",
        "  thresholds = np.arange(0, 4, 0.01)\n",
        "  actual_issame = np.asarray(issame_list)\n",
        "  nrof_folds = 10\n",
        "  embeddings1 = embeddings[0::2]\n",
        "  embeddings2 = embeddings[1::2]\n",
        "  assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
        "  assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
        "  nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
        "  nrof_thresholds = len(thresholds)\n",
        "  k_fold = LFold(n_splits=nrof_folds, shuffle=False)\n",
        "  \n",
        "  tprs = np.zeros((nrof_folds,nrof_thresholds))\n",
        "  fprs = np.zeros((nrof_folds,nrof_thresholds))\n",
        "  \n",
        "  #\n",
        "  tp, fp, tn, fn = np.zeros((nrof_folds,nrof_thresholds)), np.zeros((nrof_folds,nrof_thresholds)), np.zeros((nrof_folds,nrof_thresholds)), np.zeros((nrof_folds,nrof_thresholds))\n",
        "  #\n",
        "  \n",
        "  accuracy = np.zeros((nrof_folds))\n",
        "  indices = np.arange(nrof_pairs)\n",
        "  \n",
        "  diff = np.subtract(embeddings1, embeddings2)\n",
        "  dist = np.sum(np.square(diff),1)\n",
        "  data = data_list[0]\n",
        "\n",
        "  pouts = []\n",
        "  nouts = []\n",
        "  \n",
        "  for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
        "       \n",
        "      # Find the best threshold for the fold\n",
        "      acc_train = np.zeros((nrof_thresholds))\n",
        "      #print(train_set)\n",
        "      #print(train_set.__class__)\n",
        "      for threshold_idx, threshold in enumerate(thresholds):\n",
        "          p2 = dist[train_set]\n",
        "          p3 = actual_issame[train_set]\n",
        "          _, _, acc_train[threshold_idx], _, _, _, _ = calculate_accuracy(threshold, p2, p3)\n",
        "      best_threshold_index = np.argmax(acc_train)\n",
        "      for threshold_idx, threshold in enumerate(thresholds):\n",
        "          tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _, tp[fold_idx,threshold_idx], fp[fold_idx,threshold_idx], tn[fold_idx,threshold_idx], fn[fold_idx,threshold_idx] = \\\n",
        "          calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
        "      _, _, accuracy[fold_idx], _, _, _, _ = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
        "      best_threshold = thresholds[best_threshold_index]\n",
        "      for iid in test_set:\n",
        "        ida = iid*2\n",
        "        idb = ida+1\n",
        "        asame = actual_issame[iid]\n",
        "        _dist = dist[iid]\n",
        "        violate = _dist - best_threshold\n",
        "        if not asame:\n",
        "          violate *= -1.0\n",
        "        if violate>0.0:\n",
        "          imga = data[ida].asnumpy().transpose( (1,2,0) )[...,::-1] #to bgr\n",
        "          imgb = data[idb].asnumpy().transpose( (1,2,0) )[...,::-1]\n",
        "          #print(imga.shape, imgb.shape, violate, asame, _dist)\n",
        "          if asame:\n",
        "            pouts.append( (imga, imgb, _dist, best_threshold, ida) )\n",
        "          else:\n",
        "            nouts.append( (imga, imgb, _dist, best_threshold, ida) )\n",
        "\n",
        "        \n",
        "  tpr = np.mean(tprs,0)\n",
        "  fpr = np.mean(fprs,0)\n",
        "  acc = np.mean(accuracy)\n",
        "  pouts = sorted(pouts, key = lambda x: x[2], reverse=True)\n",
        "  nouts = sorted(nouts, key = lambda x: x[2], reverse=False)\n",
        "  print(len(pouts), len(nouts))\n",
        "  print('acc', acc)\n",
        "  #print('Tpr', tpr)\n",
        "  #print('Fpr', fpr)\n",
        "  gap = 10\n",
        "  image_shape = (112,224,3)\n",
        "  out_dir = \"./badcases\"\n",
        "  if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)\n",
        "  if len(nouts)>0:\n",
        "    threshold = nouts[0][3]\n",
        "  else:\n",
        "    threshold = pouts[-1][3]\n",
        "  \n",
        "  for item in [(pouts, 'positive(false_negative).png'), (nouts, 'negative(false_positive).png')]:\n",
        "    cols = 4\n",
        "    rows = 8000\n",
        "    outs = item[0]\n",
        "    if len(outs)==0:\n",
        "      continue\n",
        "    #if len(outs)==9:\n",
        "    #  cols = 3\n",
        "    #  rows = 3\n",
        "\n",
        "    _rows = int(math.ceil(len(outs)/cols))\n",
        "    rows = min(rows, _rows)\n",
        "    hack = {}\n",
        "\n",
        "    if name.startswith('cfp') and item[1].startswith('pos'):\n",
        "      hack = {0:'manual/238_13.jpg.jpg', 6:'manual/088_14.jpg.jpg', 10:'manual/470_14.jpg.jpg', 25:'manual/238_13.jpg.jpg', 28:'manual/143_11.jpg.jpg'}\n",
        "\n",
        "    filename = item[1]\n",
        "    if len(name)>0:\n",
        "      filename = name+\"_\"+filename\n",
        "    filename = os.path.join(out_dir, filename)\n",
        "    img = np.zeros( (image_shape[0]*rows+20, image_shape[1]*cols+(cols-1)*gap, 3), dtype=np.uint8 )\n",
        "    img[:,:,:] = 255\n",
        "    text_color = (0,0,153)\n",
        "    text_color = (255,178,102)\n",
        "    text_color = (153,255,51)\n",
        "    for outi, out in enumerate(outs):\n",
        "      row = outi//cols\n",
        "      col = outi%cols\n",
        "      if row==rows:\n",
        "        break\n",
        "      imga = out[0].copy()\n",
        "      imgb = out[1].copy()\n",
        "      if outi in hack:\n",
        "        idx = out[4]\n",
        "        print('noise idx',idx)\n",
        "        aa = hack[outi]\n",
        "        imgb = cv2.imread(aa)\n",
        "        #if aa==1:\n",
        "        #  imgb = cv2.transpose(imgb)\n",
        "        #  imgb = cv2.flip(imgb, 1)\n",
        "        #elif aa==3:\n",
        "        #  imgb = cv2.transpose(imgb)\n",
        "        #  imgb = cv2.flip(imgb, 0)\n",
        "        #else:\n",
        "        #  for ii in range(2):\n",
        "        #    imgb = cv2.transpose(imgb)\n",
        "        #    imgb = cv2.flip(imgb, 1)\n",
        "      dist = out[2]\n",
        "      _img = np.concatenate( (imga, imgb), axis=1 )\n",
        "      k = \"%.3f\"%dist\n",
        "      #print(k)\n",
        "      font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "      cv2.putText(_img,k,(80,image_shape[0]//2+7), font, 0.6, text_color, 2)\n",
        "      #_filename = filename+\"_%d.png\"%outi\n",
        "      #cv2.imwrite(_filename, _img)\n",
        "      img[row*image_shape[0]:(row+1)*image_shape[0], (col*image_shape[1]+gap*col):((col+1)*image_shape[1]+gap*col),:] = _img\n",
        "    #threshold = outs[0][3]\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    k = \"threshold: %.3f\"%threshold\n",
        "    cv2.putText(img,k,(img.shape[1]//2-70,img.shape[0]-5), font, 0.6, text_color, 2)\n",
        "    cv2.imwrite(filename, img)\n",
        "  return tp, fp, tn, fn\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX7txPGaOfOR",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title test badcase { form-width: \"45px\" }\n",
        "\n",
        "def test_badcase(data_set, mx_model, batch_size, name='', data_extra = None, label_shape = None):\n",
        "  print('testing verification badcase..')\n",
        "  data_list = data_set[0]\n",
        "  issame_list = data_set[1]\n",
        "  model = mx_model\n",
        "  embeddings_list = []\n",
        "  if data_extra is not None:\n",
        "    _data_extra = nd.array(data_extra)\n",
        "  time_consumed = 0.0\n",
        "  if label_shape is None:\n",
        "    _label = nd.ones( (batch_size,) )\n",
        "  else:\n",
        "    _label = nd.ones( label_shape )\n",
        "  for i in range( len(data_list) ):\n",
        "    data = data_list[i]\n",
        "    embeddings = None\n",
        "    ba = 0\n",
        "    while ba<data.shape[0]:\n",
        "      bb = min(ba+batch_size, data.shape[0])\n",
        "      count = bb-ba\n",
        "      _data = nd.slice_axis(data, axis=0, begin=bb-batch_size, end=bb)\n",
        "      #print(_data.shape, _label.shape)\n",
        "      time0 = datetime.datetime.now()\n",
        "      if data_extra is None:\n",
        "        db = mx.io.DataBatch(data=(_data,), label=(_label,))\n",
        "      else:\n",
        "        db = mx.io.DataBatch(data=(_data,_data_extra), label=(_label,))\n",
        "      model.forward(db, is_train=False)\n",
        "      net_out = model.get_outputs()\n",
        "      _embeddings = net_out[0].asnumpy()\n",
        "      time_now = datetime.datetime.now()\n",
        "      diff = time_now - time0\n",
        "      time_consumed+=diff.total_seconds()\n",
        "      if embeddings is None:\n",
        "        embeddings = np.zeros( (data.shape[0], _embeddings.shape[1]) )\n",
        "      embeddings[ba:bb,:] = _embeddings[(batch_size-count):,:]\n",
        "      ba = bb\n",
        "    embeddings_list.append(embeddings)\n",
        "  embeddings = embeddings_list[0] + embeddings_list[1]\n",
        "  embeddings = sklearn.preprocessing.normalize(embeddings)\n",
        "  thresholds = np.arange(0, 4, 0.01)\n",
        "  actual_issame = np.asarray(issame_list)\n",
        "  nrof_folds = 10\n",
        "  embeddings1 = embeddings[0::2]\n",
        "  embeddings2 = embeddings[1::2]\n",
        "  assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
        "  assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
        "  nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
        "  nrof_thresholds = len(thresholds)\n",
        "  k_fold = LFold(n_splits=nrof_folds, shuffle=False)\n",
        "  \n",
        "  tprs = np.zeros((nrof_folds,nrof_thresholds))\n",
        "  fprs = np.zeros((nrof_folds,nrof_thresholds))\n",
        "  accuracy = np.zeros((nrof_folds))\n",
        "  indices = np.arange(nrof_pairs)\n",
        "  \n",
        "  diff = np.subtract(embeddings1, embeddings2)\n",
        "  dist = np.sum(np.square(diff),1)\n",
        "  data = data_list[0]\n",
        "\n",
        "  pouts = []\n",
        "  nouts = []\n",
        "  \n",
        "  for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
        "       \n",
        "      # Find the best threshold for the fold\n",
        "      acc_train = np.zeros((nrof_thresholds))\n",
        "      #print(train_set)\n",
        "      #print(train_set.__class__)\n",
        "      for threshold_idx, threshold in enumerate(thresholds):\n",
        "          p2 = dist[train_set]\n",
        "          p3 = actual_issame[train_set]\n",
        "          _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, p2, p3)\n",
        "      best_threshold_index = np.argmax(acc_train)\n",
        "      for threshold_idx, threshold in enumerate(thresholds):\n",
        "          tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
        "      _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
        "      best_threshold = thresholds[best_threshold_index]\n",
        "      for iid in test_set:\n",
        "        ida = iid*2\n",
        "        idb = ida+1\n",
        "        asame = actual_issame[iid]\n",
        "        _dist = dist[iid]\n",
        "        violate = _dist - best_threshold\n",
        "        if not asame:\n",
        "          violate *= -1.0\n",
        "        if violate>0.0:\n",
        "          imga = data[ida].asnumpy().transpose( (1,2,0) )[...,::-1] #to bgr\n",
        "          imgb = data[idb].asnumpy().transpose( (1,2,0) )[...,::-1]\n",
        "          #print(imga.shape, imgb.shape, violate, asame, _dist)\n",
        "          if asame:\n",
        "            pouts.append( (imga, imgb, _dist, best_threshold, ida) )\n",
        "          else:\n",
        "            nouts.append( (imga, imgb, _dist, best_threshold, ida) )\n",
        "\n",
        "        \n",
        "  tpr = np.mean(tprs,0)\n",
        "  fpr = np.mean(fprs,0)\n",
        "  acc = np.mean(accuracy)\n",
        "  pouts = sorted(pouts, key = lambda x: x[2], reverse=True)\n",
        "  nouts = sorted(nouts, key = lambda x: x[2], reverse=False)\n",
        "  print(len(pouts), len(nouts))\n",
        "  print('acc', acc)\n",
        "  gap = 10\n",
        "  image_shape = (112,224,3)\n",
        "  out_dir = \"./badcases\"\n",
        "  if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)\n",
        "  if len(nouts)>0:\n",
        "    threshold = nouts[0][3]\n",
        "  else:\n",
        "    threshold = pouts[-1][3]\n",
        "  \n",
        "  for item in [(pouts, 'positive(false_negative).png'), (nouts, 'negative(false_positive).png')]:\n",
        "    cols = 4\n",
        "    rows = 8000\n",
        "    outs = item[0]\n",
        "    if len(outs)==0:\n",
        "      continue\n",
        "    #if len(outs)==9:\n",
        "    #  cols = 3\n",
        "    #  rows = 3\n",
        "\n",
        "    _rows = int(math.ceil(len(outs)/cols))\n",
        "    rows = min(rows, _rows)\n",
        "    hack = {}\n",
        "\n",
        "    if name.startswith('cfp') and item[1].startswith('pos'):\n",
        "      hack = {0:'manual/238_13.jpg.jpg', 6:'manual/088_14.jpg.jpg', 10:'manual/470_14.jpg.jpg', 25:'manual/238_13.jpg.jpg', 28:'manual/143_11.jpg.jpg'}\n",
        "\n",
        "    filename = item[1]\n",
        "    if len(name)>0:\n",
        "      filename = name+\"_\"+filename\n",
        "    filename = os.path.join(out_dir, filename)\n",
        "    img = np.zeros( (image_shape[0]*rows+20, image_shape[1]*cols+(cols-1)*gap, 3), dtype=np.uint8 )\n",
        "    img[:,:,:] = 255\n",
        "    text_color = (0,0,153)\n",
        "    text_color = (255,178,102)\n",
        "    text_color = (153,255,51)\n",
        "    for outi, out in enumerate(outs):\n",
        "      row = outi//cols\n",
        "      col = outi%cols\n",
        "      if row==rows:\n",
        "        break\n",
        "      imga = out[0].copy()\n",
        "      imgb = out[1].copy()\n",
        "      if outi in hack:\n",
        "        idx = out[4]\n",
        "        print('noise idx',idx)\n",
        "        aa = hack[outi]\n",
        "        imgb = cv2.imread(aa)\n",
        "        #if aa==1:\n",
        "        #  imgb = cv2.transpose(imgb)\n",
        "        #  imgb = cv2.flip(imgb, 1)\n",
        "        #elif aa==3:\n",
        "        #  imgb = cv2.transpose(imgb)\n",
        "        #  imgb = cv2.flip(imgb, 0)\n",
        "        #else:\n",
        "        #  for ii in range(2):\n",
        "        #    imgb = cv2.transpose(imgb)\n",
        "        #    imgb = cv2.flip(imgb, 1)\n",
        "      dist = out[2]\n",
        "      _img = np.concatenate( (imga, imgb), axis=1 )\n",
        "      k = \"%.3f\"%dist\n",
        "      #print(k)\n",
        "      font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "      cv2.putText(_img,k,(80,image_shape[0]//2+7), font, 0.6, text_color, 2)\n",
        "      #_filename = filename+\"_%d.png\"%outi\n",
        "      #cv2.imwrite(_filename, _img)\n",
        "      img[row*image_shape[0]:(row+1)*image_shape[0], (col*image_shape[1]+gap*col):((col+1)*image_shape[1]+gap*col),:] = _img\n",
        "    #threshold = outs[0][3]\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    k = \"threshold: %.3f\"%threshold\n",
        "    cv2.putText(img,k,(img.shape[1]//2-70,img.shape[0]-5), font, 0.6, text_color, 2)\n",
        "    cv2.imwrite(filename, img)\n",
        "\n",
        "def dumpR(data_set, mx_model, batch_size, name='', data_extra = None, label_shape = None):\n",
        "  print('dump verification embedding..')\n",
        "  data_list = data_set[0]\n",
        "  issame_list = data_set[1]\n",
        "  model = mx_model\n",
        "  embeddings_list = []\n",
        "  if data_extra is not None:\n",
        "    _data_extra = nd.array(data_extra)\n",
        "  time_consumed = 0.0\n",
        "  if label_shape is None:\n",
        "    _label = nd.ones( (batch_size,) )\n",
        "  else:\n",
        "    _label = nd.ones( label_shape )\n",
        "  for i in range( len(data_list) ):\n",
        "    data = data_list[i]\n",
        "    embeddings = None\n",
        "    ba = 0\n",
        "    while ba<data.shape[0]:\n",
        "      bb = min(ba+batch_size, data.shape[0])\n",
        "      count = bb-ba\n",
        "      _data = nd.slice_axis(data, axis=0, begin=bb-batch_size, end=bb)\n",
        "      #print(_data.shape, _label.shape)\n",
        "      time0 = datetime.datetime.now()\n",
        "      if data_extra is None:\n",
        "        db = mx.io.DataBatch(data=(_data,), label=(_label,))\n",
        "      else:\n",
        "        db = mx.io.DataBatch(data=(_data,_data_extra), label=(_label,))\n",
        "      model.forward(db, is_train=False)\n",
        "      net_out = model.get_outputs()\n",
        "      _embeddings = net_out[0].asnumpy()\n",
        "      time_now = datetime.datetime.now()\n",
        "      diff = time_now - time0\n",
        "      time_consumed+=diff.total_seconds()\n",
        "      if embeddings is None:\n",
        "        embeddings = np.zeros( (data.shape[0], _embeddings.shape[1]) )\n",
        "      embeddings[ba:bb,:] = _embeddings[(batch_size-count):,:]\n",
        "      ba = bb\n",
        "    embeddings_list.append(embeddings)\n",
        "  embeddings = embeddings_list[0] + embeddings_list[1]\n",
        "  embeddings = sklearn.preprocessing.normalize(embeddings)\n",
        "  actual_issame = np.asarray(issame_list)\n",
        "  outname = os.path.join('temp.bin')\n",
        "  with open(outname, 'wb') as f:\n",
        "    pickle.dump((embeddings, issame_list), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_FjfDjGN-N7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title test\n",
        "def test(data_set, mx_model, batch_size, nfolds=10, data_extra = None, label_shape = None):\n",
        "  print('testing verification..')\n",
        "  county = 0\n",
        "  data_list = data_set[0]\n",
        "  issame_list = data_set[1]\n",
        "  model = mx_model\n",
        "  embeddings_list = []\n",
        "  if data_extra is not None:\n",
        "    _data_extra = nd.array(data_extra)\n",
        "  time_consumed = 0.0\n",
        "  if label_shape is None:\n",
        "    _label = nd.ones( (batch_size,) )\n",
        "  else:\n",
        "    _label = nd.ones( label_shape )\n",
        "  for i in range( len(data_list) ):\n",
        "  #for i in range( 10 ):\n",
        "    data = data_list[i]\n",
        "    embeddings = None\n",
        "    ba = 0\n",
        "    while ba<data.shape[0]:\n",
        "    #while ba < 10:\n",
        "      bb = min(ba+batch_size, data.shape[0])\n",
        "      count = bb-ba\n",
        "      _data = nd.slice_axis(data, axis=0, begin=bb-batch_size, end=bb)\n",
        "      #print(_data.shape, _label.shape)\n",
        "      time0 = datetime.datetime.now()\n",
        "      if data_extra is None:\n",
        "        db = mx.io.DataBatch(data=(_data,), label=(_label,))\n",
        "      else:\n",
        "        db = mx.io.DataBatch(data=(_data,_data_extra), label=(_label,))\n",
        "      model.forward(db, is_train=False)\n",
        "      net_out = model.get_outputs()\n",
        "      #_arg, _aux = model.get_params()\n",
        "      #__arg = {}\n",
        "      #for k,v in _arg.iteritems():\n",
        "      #  __arg[k] = v.as_in_context(_ctx)\n",
        "      #_arg = __arg\n",
        "      #_arg[\"data\"] = _data.as_in_context(_ctx)\n",
        "      #_arg[\"softmax_label\"] = _label.as_in_context(_ctx)\n",
        "      #for k,v in _arg.iteritems():\n",
        "      #  print(k,v.context)\n",
        "      #exe = sym.bind(_ctx, _arg ,args_grad=None, grad_req=\"null\", aux_states=_aux)\n",
        "      #exe.forward(is_train=False)\n",
        "      #net_out = exe.outputs\n",
        "      _embeddings = net_out[0].asnumpy()\n",
        "      time_now = datetime.datetime.now()\n",
        "      diff = time_now - time0\n",
        "      time_consumed+=diff.total_seconds()\n",
        "      county += 1\n",
        "      print(county)\n",
        "      #print(_embeddings.shape)\n",
        "      if embeddings is None:\n",
        "        embeddings = np.zeros( (data.shape[0], _embeddings.shape[1]) )\n",
        "      embeddings[ba:bb,:] = _embeddings[(batch_size-count):,:]\n",
        "      ba = bb\n",
        "    embeddings_list.append(embeddings)\n",
        "\n",
        "  _xnorm = 0.0\n",
        "  _xnorm_cnt = 0\n",
        "  for embed in embeddings_list:\n",
        "    for i in range(embed.shape[0]):\n",
        "      _em = embed[i]\n",
        "      _norm=np.linalg.norm(_em)\n",
        "      #print(_em.shape, _norm)\n",
        "      _xnorm+=_norm\n",
        "      _xnorm_cnt+=1\n",
        "  _xnorm /= _xnorm_cnt\n",
        "\n",
        "  embeddings = embeddings_list[0].copy()\n",
        "  embeddings = sklearn.preprocessing.normalize(embeddings)\n",
        "  acc1 = 0.0\n",
        "  std1 = 0.0\n",
        "  #_, _, accuracy, val, val_std, far = evaluate(embeddings, issame_list, nrof_folds=10)\n",
        "  #acc1, std1 = np.mean(accuracy), np.std(accuracy)\n",
        "\n",
        "  #print('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))\n",
        "  #embeddings = np.concatenate(embeddings_list, axis=1)\n",
        "  embeddings = embeddings_list[0] + embeddings_list[1]\n",
        "  embeddings = sklearn.preprocessing.normalize(embeddings)\n",
        "  print(embeddings.shape)\n",
        "  print('infer time', time_consumed)\n",
        "  #_, _, accuracy, val, val_std, far = evaluate(embeddings, issame_list, nrof_folds=nfolds)\n",
        "  tpr, fpr, accuracy, val, val_std, far = evaluate(embeddings, issame_list, nrof_folds=nfolds)\n",
        "  acc2, std2 = np.mean(accuracy), np.std(accuracy)\n",
        "  return acc1, std1, acc2, std2, _xnorm, embeddings_list, tpr, fpr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pC0snB1ORYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title plot_roc_and_prc\n",
        "def plot_roc_and_prc(true_positive_count,\n",
        "                     false_positive_count,\n",
        "                     true_negative_count,\n",
        "                     false_negative_count):\n",
        "\n",
        "    true_positive_rate = np.divide(true_positive_count, true_positive_count + false_negative_count)\n",
        "    false_positive_rate = np.divide(false_positive_count, false_positive_count + true_negative_count)\n",
        "    print(\"True Pos Rate:\", true_positive_rate)\n",
        "    print(\"\\n\")\n",
        "    print(\"False Pos Rate:\", false_positive_rate)\n",
        "    precision_rate = np.divide(true_positive_count, true_positive_count + false_positive_count)\n",
        "    recall_rate = np.divide(true_positive_count, true_positive_count + false_negative_count)\n",
        "    print(\"Precision Rate:\", precision_rate)\n",
        "    print(\"\\n\")\n",
        "    print(\"Recall Rate:\", recall_rate)\n",
        "\n",
        "    f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
        "    ax1.plot(false_positive_rate, true_positive_rate)\n",
        "    ax1.set_title('ROC')\n",
        "    ax1.set_xlabel('False Positive Rate')\n",
        "    ax1.set_ylabel('True Positive Rate')\n",
        "    ax1.set_xlim(-1, 2)\n",
        "    ax1.set_ylim(-1, 2)\n",
        "\n",
        "    ax2.plot(recall_rate, precision_rate)\n",
        "    ax2.set_title('PRC')\n",
        "    ax2.set_xlabel('Recall')\n",
        "    ax2.set_ylabel('Precision')\n",
        "    ax2.set_xlim(-1, 2)\n",
        "    ax2.set_ylim(-1, 2)\n",
        "\n",
        "    return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8aBxyZ8OXhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title plot accuracy\n",
        "def plot_accuracy(true_positive_count,\n",
        "                  true_negative_count,\n",
        "                  num_tests,\n",
        "                  thresholds):\n",
        "\n",
        "    correct_match_count = true_positive_count + true_negative_count\n",
        "    correct_match_rate = correct_match_count / num_tests\n",
        "    \n",
        "\n",
        "    max_ind, threshold_at_max_correct_rate, max_correct_rate = \\\n",
        "        select_best_threshold(true_positive_count,\n",
        "                                               true_negative_count,\n",
        "                                               num_tests,\n",
        "                                               thresholds)\n",
        "\n",
        "    print(correct_match_count[0], correct_match_rate[0], max_correct_rate, threshold_at_max_correct_rate)\n",
        "    f, ax = plt.subplots(1, 1, sharey=True)\n",
        "    title = 'Accuracy (max = ' + '%.4f' % max_correct_rate + ' at threshold = ' \\\n",
        "            + '%.2f' % threshold_at_max_correct_rate + ')'\n",
        "    ax.plot(thresholds, correct_match_rate)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('Threshold')\n",
        "    ax.set_ylabel('Accuracy')\n",
        "    ax.set_ylim(0, 1)\n",
        "\n",
        "    return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV5m96HXOZM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title select best threshold\n",
        "def select_best_threshold(true_positive_count,\n",
        "                          true_negative_count,\n",
        "                          num_tests,\n",
        "                          thresholds):\n",
        "\n",
        "    correct_match_count = true_positive_count + true_negative_count\n",
        "    correct_match_rate = correct_match_count / num_tests\n",
        "\n",
        "    max_ind = np.argmax(correct_match_rate)\n",
        "    threshold_at_max_correct_rate = thresholds[max_ind]\n",
        "    max_correct_rate = correct_match_rate[max_ind]\n",
        "\n",
        "    return max_ind, threshold_at_max_correct_rate, max_correct_rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcIyy60kJIOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Arguments\n",
        "class Arguments(object):\n",
        "  \n",
        "  def __init__(self):\n",
        "    # Path to dataset\n",
        "    self.data_dir = '../../datasets/faces_emore/'\n",
        "    # Path to model file\n",
        "    self.model = '../../models/model-r50-am-lfw/model,0'\n",
        "    # Verification targets\n",
        "    self.target = 'lfw'#'lfw,cfp_ff,cfp_fp,agedb_30'\n",
        "    # Batch size\n",
        "    self.batch_size = 1\n",
        "    # Number of folds for cross validation\n",
        "    self.nfolds = 1\n",
        "    self.gpu = 0\n",
        "    self.mode = 0\n",
        "    self.max = ''\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LWpEFgQCM_E",
        "colab_type": "code",
        "outputId": "a8c9f845-ffcb-452a-cfd1-43acb4e20541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "#@title main\n",
        "if __name__ == '__main__':\n",
        "\n",
        "  #parser = argparse.ArgumentParser(description='do verification')\n",
        "  # general\n",
        "  #!python verification.py --data-dir ../../datasets/faces_emore/ --model ../../models/model-r50-am-lfw/model,0 --batch-size 1 --nfolds 1\n",
        "#   parser.add_argument('--data-dir', default='../../datasets/faces_emore/', help='')\n",
        "#   parser.add_argument('--model', default='../../models/model-r50-am-lfw/model,0', help='path to load model.')\n",
        "#   parser.add_argument('--target', default='lfw,cfp_ff,cfp_fp,agedb_30', help='test targets.')\n",
        "#   parser.add_argument('--gpu', default=0, type=int, help='gpu id')\n",
        "#   parser.add_argument('--batch-size', default=1, type=int, help='')\n",
        "#   parser.add_argument('--max', default='', type=str, help='')\n",
        "#   parser.add_argument('--mode', default=0, type=int, help='')\n",
        "#   parser.add_argument('--nfolds', default=1, type=int, help='')\n",
        "  args = Arguments()#parser.parse_args()\n",
        "\n",
        "  prop = face_image.load_property(args.data_dir)\n",
        "  image_size = prop.image_size\n",
        "  print('image_size', image_size)\n",
        "  ctx = mx.gpu(args.gpu)\n",
        "  nets = []\n",
        "  vec = args.model.split(',')\n",
        "  prefix = args.model.split(',')[0]\n",
        "  epochs = []\n",
        "  if len(vec)==1:\n",
        "    pdir = os.path.dirname(prefix)\n",
        "    for fname in os.listdir(pdir):\n",
        "      if not fname.endswith('.params'):\n",
        "        continue\n",
        "      _file = os.path.join(pdir, fname)\n",
        "      if _file.startswith(prefix):\n",
        "        epoch = int(fname.split('.')[0].split('-')[1])\n",
        "        epochs.append(epoch)\n",
        "    epochs = sorted(epochs, reverse=True)\n",
        "    if len(args.max)>0:\n",
        "      _max = [int(x) for x in args.max.split(',')]\n",
        "      assert len(_max)==2\n",
        "      if len(epochs)>_max[1]:\n",
        "        epochs = epochs[_max[0]:_max[1]]\n",
        "\n",
        "  else:\n",
        "    epochs = [int(x) for x in vec[1].split('|')]\n",
        "  print('model number', len(epochs))\n",
        "  time0 = datetime.datetime.now()\n",
        "  for epoch in epochs:\n",
        "    print('loading',prefix, epoch)\n",
        "    sym, arg_params, aux_params = mx.model.load_checkpoint(prefix, epoch)\n",
        "    #arg_params, aux_params = ch_dev(arg_params, aux_params, ctx)\n",
        "    all_layers = sym.get_internals()\n",
        "    sym = all_layers['fc1_output']\n",
        "    model = mx.mod.Module(symbol=sym, context=ctx, label_names = None)\n",
        "    #model.bind(data_shapes=[('data', (args.batch_size, 3, image_size[0], image_size[1]))], label_shapes=[('softmax_label', (args.batch_size,))])\n",
        "    model.bind(data_shapes=[('data', (args.batch_size, 3, image_size[0], image_size[1]))])\n",
        "    model.set_params(arg_params, aux_params)\n",
        "    nets.append(model)\n",
        "  time_now = datetime.datetime.now()\n",
        "  diff = time_now - time0\n",
        "  print('model loading time', diff.total_seconds())\n",
        "\n",
        "  ver_list = []\n",
        "  ver_name_list = []\n",
        "  for name in args.target.split(','):\n",
        "    path = os.path.join(args.data_dir,name+\".bin\")\n",
        "    if os.path.exists(path):\n",
        "      print('loading.. ', name)\n",
        "      data_set = load_bin(path, image_size)\n",
        "      ver_list.append(data_set)\n",
        "      ver_name_list.append(name)\n",
        "\n",
        "  if args.mode==0:\n",
        "    for i in range(len(ver_list)):\n",
        "      results = []\n",
        "      for model in nets:\n",
        "        acc1, std1, acc2, std2, xnorm, embeddings_list = test(ver_list[i], model, args.batch_size, args.nfolds)\n",
        "        print('[%s]XNorm: %f' % (ver_name_list[i], xnorm))\n",
        "        print('[%s]Accuracy: %1.5f+-%1.5f' % (ver_name_list[i], acc1, std1))\n",
        "        print('[%s]Accuracy-Flip: %1.5f+-%1.5f' % (ver_name_list[i], acc2, std2))\n",
        "        results.append(acc2)\n",
        "      print('Max of [%s] is %1.5f' % (ver_name_list[i], np.max(results)))\n",
        "  elif args.mode==1:\n",
        "    model = nets[0]\n",
        "    test_badcase(ver_list[0], model, args.batch_size, args.target)\n",
        "  else:\n",
        "    model = nets[0]\n",
        "    dumpR(ver_list[0], model, args.batch_size, args.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image_size [112, 112]\n",
            "model number 1\n",
            "loading ../../models/model-r50-am-lfw/model 0\n",
            "model loading time 0.297829\n",
            "loading..  lfw\n",
            "loading bin 0\n",
            "loading bin 1000\n",
            "loading bin 2000\n",
            "loading bin 3000\n",
            "loading bin 4000\n",
            "loading bin 5000\n",
            "loading bin 6000\n",
            "loading bin 7000\n",
            "loading bin 8000\n",
            "loading bin 9000\n",
            "loading bin 10000\n",
            "loading bin 11000\n",
            "(12000, 3, 112, 112)\n",
            "testing verification..\n",
            "(12000, 512)\n",
            "infer time 532.9397990000028\n",
            "[lfw]XNorm: 21.949640\n",
            "[lfw]Accuracy: 0.00000+-0.00000\n",
            "[lfw]Accuracy-Flip: 0.99817+-0.00000\n",
            "Max of [lfw] is 0.99817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CiOApG3SYeg",
        "colab_type": "code",
        "outputId": "ef9245fe-f69f-403c-9c96-091a674caef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(ver_list[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh6FvKhiJCAL",
        "colab_type": "code",
        "outputId": "9ee19536-a091-4759-d82e-ad0ef4880597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "source": [
        "#@title test bed\n",
        "#   ver_list = []\n",
        "#   ver_name_list = []\n",
        "#   print(\"Getting bins\")\n",
        "#   for name in args.target.split(','):\n",
        "#     path = os.path.join(args.data_dir,name+\".bin\")\n",
        "#     if os.path.exists(path):\n",
        "#       print('loading.. ', name)\n",
        "#       data_set = load_bin(path, image_size)\n",
        "#       ver_list.append(data_set)\n",
        "#       ver_name_list.append(name)\n",
        "  \n",
        "  if args.mode==0:\n",
        "    for i in range(len(ver_list)):\n",
        "      results = []\n",
        "      for model in nets:\n",
        "        acc1, std1, acc2, std2, xnorm, embeddings_list, tpr, fpr = test(ver_list[i], model, args.batch_size, args.nfolds)\n",
        "        print('[%s]XNorm: %f' % (ver_name_list[i], xnorm))\n",
        "        print('[%s]Accuracy: %1.5f+-%1.5f' % (ver_name_list[i], acc1, std1))\n",
        "        print('[%s]Accuracy-Flip: %1.5f+-%1.5f' % (ver_name_list[i], acc2, std2))\n",
        "        \n",
        "        print('[LFW]TPR & FPR: ', (ver_name_list[i], np.mean(tpr), np.mean(fpr) ))\n",
        "        \n",
        "        results.append(acc2)\n",
        "      print('Max of [%s] is %1.5f' % (ver_name_list[i], np.max(results)))\n",
        "  elif args.mode==1:\n",
        "    model = nets[0]\n",
        "    test_badcase(ver_list[0], model, args.batch_size, args.target)\n",
        "  else:\n",
        "    model = nets[0]\n",
        "    dumpR(ver_list[0], model, args.batch_size, args.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing verification..\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "(12000, 512)\n",
            "infer time 0.4500439999999999\n",
            "[lfw]XNorm: 0.018038\n",
            "[lfw]Accuracy: 0.00000+-0.00000\n",
            "[lfw]Accuracy-Flip: 0.50000+-0.00000\n",
            "[LFW]TPR & FPR:  ('lfw', 0.9973333333333333, 0.9975)\n",
            "Max of [lfw] is 0.50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_TcfH_sT289",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI7dN0fLUjW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsVu4HepacZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5-TkYBQaeAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roc_auc = auc(fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFo_uHIJawac",
        "colab_type": "code",
        "outputId": "1a248880-4bb7-4b6b-94d4-60776a03105c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "roc_auc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49916666666666665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tHIv13Sa0Lc",
        "colab_type": "code",
        "outputId": "a4174648-4523-4a73-d3fa-fb561fc3d1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "model = nets[0]\n",
        "tp, fp, tn, fn = mod_test_badcase(ver_list[0], model, args.batch_size, args.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing verification badcase..\n",
            "11 1\n",
            "acc 0.998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G7sRs3ge5gu",
        "colab_type": "code",
        "outputId": "b39a3bce-8ce3-4225-c868-2d534334bc08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ts_fs_counter.tnc, ts_fs_counter.fnc, ts_fs_counter.fpc, ts_fs_counter.tpc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 0, 0, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZu6IHw5z92K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_roc_and_prc(ts_fs_counter.tpc, ts_fs_counter.fpc, ts_fs_counter.tnc, ts_fs_counter.fnc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg3sJcXp0MaJ",
        "colab_type": "code",
        "outputId": "0d2c2ee6-1bfb-4924-a722-2320899584d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "plot_roc_and_prc(tp, fp, tn, fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Pos Rate: [[0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]]\n",
            "\n",
            "\n",
            "False Pos Rate: [[0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]]\n",
            "Precision Rate: [[nan nan nan ... 0.5 0.5 0.5]\n",
            " [nan nan nan ... 0.5 0.5 0.5]\n",
            " [nan nan nan ... 0.5 0.5 0.5]\n",
            " ...\n",
            " [nan nan nan ... 0.5 0.5 0.5]\n",
            " [nan nan nan ... 0.5 0.5 0.5]\n",
            " [nan nan nan ... 0.5 0.5 0.5]]\n",
            "\n",
            "\n",
            "Recall Rate: [[0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]\n",
            " [0. 0. 0. ... 1. 1. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcFPWdxvHPw30rAiuIcilR8UIY\nFa/EeJt4xQM1rseahMSYqGuyieZQY9zNpW48Y1jNesQrxtuQGAXPLFFHBUHwQAIBggqKQBCQ47t/\nVI0048xQI9NdPd3P+/XqF1XVv+769vCbebquXykiMDMzy6JN3gWYmVnr4dAwM7PMHBpmZpaZQ8PM\nzDJzaJiZWWYODTMzy8yhYWZmmTk0KpCkWZKWS/qnpLck3SSpW8Hze0maIGmppMWSHpI0rN579JD0\nS0l/T9/nzXS+d+k/kVmiXt9+u65vS3pC0op0+UJJ90rqV++1n5J0d/r8YkkvSzpPUtu8Pk9r5NCo\nXEdERDdgOLArcAGApD2BPwMPAFsAg4HJwF8kDUnbdADGAzsAhwI9gD2Bd4HdS/sxzD6mrm+PAGqA\nH6TLv5Eu3wboBlxW9wJJWwPPAnOAnSJiE+D49PXdS1h7q9cu7wKsuCLiLUmPkIQHwM+BWyLiyoJm\nP5A0ErgYODV9DAA+GxH/TNu8A/y4NFWbbVhEzJP0R2DHesvfl3Q/cFbB4h8B/xcR5xW0ew34YkmK\nrSDe0qhwkrYEDgNmSOoC7AXc3UDT3wEHpdMHAn8qCAyzsiNpK+BzwEv1lvcCjgFmFCw+EPh96aqr\nXA6NynW/pKUkm+PvABcBm5H8n89voP18oO54Ra9G2piVg/slvQ88AzwJ/Fe6/CpJi4GFJH35mwWv\ncZ9uIQ6NynV0RHQH9gO2I/klWgSsBfo10L4fyS8bJMcuGmpjVg6OjohNI2JgRHw9Ipany89Oj1Xs\nDPQEtix4jft0C3FoVLiIeBK4CbgsIpYBE0kOANY3muTgN8BjwCGSupakSLMWFBFTgEuBayUpXfwY\ncGx+VVUOh0Z1+CVwkKRdgPOB0ySdLam7pJ6SLiU5O+pHaftbSXZr3SNpO0ltJPWS9D1Jn8vnI5g1\ny83A5sCR6fxFwF6SfiGpL4CkbST9VtKmeRXZGjk0qkBELABuAS6MiGeAQ0gOFM4HZpOckrtPRLyR\ntl9JcuDwVeBRYAnwHMkurmdL/gHMmikiPgSuBH6Yzr9J8sVoEPBKeuzjHqAWWJpTma2SfBMmMzPL\nylsaZmaWWW6hIWkrSY9LmibpFUnnNNBGkq6SNCO95H9EHrWamVkizyvCVwPfiogXJXUHXpD0aERM\nK2hzGDA0fewB/Cr918zMcpDblkZEzI+IF9PppcB0oH+9ZkeRDHkREfFXYNP6g5CZmVnplMXYU5IG\nkZzBU//MnP4kp37WmZsuW+/KTkljgDEAXbt2HbnddtsVq1QzXnjhhYUR0acU63LftlLJ2q9zD410\nyO57gHMjYskneY+IGAuMBaipqYna2toWrNBsfZJml2pd7ttWKln7da5nT0lqTxIYt0XEvQ00mQds\nVTC/ZbrMzMxykOfZUwJuBKZHxBWNNHsQODU9i2oUsDgiPOiYmVlO8tw9tTdwCjBF0qR02fdI7uNA\nRFwPjCMZ+ngG8AHwbznUaWZmqdxCIx3OQhtoE6x/IxUzM8uRrwg3M7PMHBpmZpaZQ8PMzDJzaJiZ\nWWYODTMzy8yhYWZmmTk0zMwsM4eGmZll5tAwM7PMHBpmZpaZQ8PMzDJzaJiZWWYODTMzy8yhYWZm\nmTk0zMwsM4eGmZll5tAwM7PMHBpmZpaZQ8PMzDJzaJiZWWYODTMzy8yhYWZmmTk0zMwsM4eGmZll\n5tAwM7PMHBpmZpaZQ8PMzDLLNTQk/UbSO5KmNvL8fpIWS5qUPi4sdY1mZrZOu5zXfxNwDXBLE22e\njojDS1OOmZk1JdctjYh4CngvzxrMzCy71nBMY09JkyX9UdIOeRdjZlbNyj00XgQGRsQuwNXA/Q01\nkjRGUq2k2gULFpS0QLNict+2clPWoRERSyLin+n0OKC9pN4NtBsbETURUdOnT5+S12lWLO7bVm7K\nOjQk9ZWkdHp3knrfzbcqM7PqlevZU5LuAPYDekuaC1wEtAeIiOuB44AzJa0GlgMnRkTkVK6ZWdXL\nNTQi4qQNPH8NySm5ZmZWBsp695SZmZUXh4aZmWXm0DAzs8wcGmZmlplDw8zMMnNomJlZZg4NMzPL\nzKFhZmaZOTTMzCwzh4aZmWXm0DAzs8wcGmZmlplDw8zMMnNomJlZZg4NMzPLzKFhZmaZOTTMzCwz\nh4aZmWXm0DAzs8wcGmZmlplDw8zMMnNomJlZZg4NMzPLLFNoSOogaZtiF2NmZuVtg6Eh6fPAFODR\ndH64pPuKXZiZmZWfLFsalwB7AO8DRMQkwFsdZmZVKEtorIqI9+sti2IUY2Zm5a1dhjbTJY0G2kga\nDJwN/LW4ZZmZWTnKsqXxDWAksBa4F1gJnNMSK5f0G0nvSJrayPOSdJWkGZJeljSiJdZrZmafTJbQ\nOCQivhsRu6aP84HDWmj9NwGHNvH8YcDQ9DEG+FULrdfMzD6BLLunfkCyhVHo+w0sa7aIeErSoCaa\nHAXcEhEB/FXSppL6RcT8jV13ufvKf32bXUe8woOvzOHzr17CTn3WsObA87nhsa9yeO8r2eaOHZk4\nbG8O7T2c+7pNZrvP3MuZq27k9KduY/bAhxj+l3YMXXQSczbrzOrlT3DC4O9yd4eJLOvwHjvu9UfO\n+sd1/OLVy5i5+Uvc1aM7V14fTNvpUlZ98BRDOnVjZO+DGDfkWi4cej5t5y2j79TZvNDpTH622aYc\neV0XXt/mWGZ0nUT3Tx3Mbfv2YebkPty+5CK+vs0SxvxhBP1OmMFxU6Zy74D9aLfJu6xe3Itjzngg\n7x+rlYHbR19L99F385Vev+TuCWfxj+cXsXDQNaxYdAVLt69h30/fyukv/Jrbl1zELf3fZreJ57Fs\n9VT27b0nL/ZYxGbD76Jnz7f4CRcyVbvQ6ZF5HDToHA68vwNrepzF2+1f+ajtP9q+xzOfHrxeu/N+\n2Z4J+13LHh3n0bfzIMa1f4mtP3slJ+seOj0yj+7bn8+YP4xg0OjZ9Jr2Ia/OOJlbT+7Fty7/MT33\n2YSXVh5Nm2GP8+x7o/jC43cwacfDufiSy/L+sZZMo1sakg6R9N9Af0lXFDxuINlVVQr9gTkF83PT\nZfVrHSOpVlLtggULSlRacX3YpiNtVsHK9iC1pRPtWbWqA3OjN4vbtGVVu66wej5d2m/CSq2mEyug\nrZi5th8HL/uAN/uJHktnobY9adNuEADdoxNr17alIyth5VoG6m3+3j753jC7z1pAxJoFdG7XDYAl\nS3rTNZaytnsHltA1p59EdavEvl0J4r32HDp7Cd2+sYqBf5uVdzklpeRLfANPSLsCI4ALSU67rbMU\nmBARC1ukgGRL4+GI2LGB5x4GfhoRz6Tz44HvRkRtY+9XU1MTtbWNPt1qXHrxmSxot4Jtu/XinR69\n6P/WCvovgxUHDmf52g70f/8F+vY4gl4D+tBzwOYs+udcOvXoxbxlbRjSfiUdOnSAjt03qoaIQNK6\naYB0vppJeiEiakq93krp25Ug1q7liBuvZvDKX7Nyk2MYe8qleZe00bL260Z3T0XES8BLkm6LiBUt\nWl1284CtCua3TJdVvJ12eAWAo47/30ZafH69uT6dBwOwXUeAbi1SgwoCQg4Ls3Uk9O7/cMy4kdx1\n+MNA6w+NrLIcCO8v6c707KXX6x5FryzxIHBqehbVKGBxNRzPAJgz6XDmTDo87zLMrBFHTv8hk7bq\nxt7PfibvUkoqy4Hwm0hi9DKSs5n+jRa6uE/SHcB+QG9Jc4GLgPYAEXE9MA74HDAD+CBdd1XYueND\n6dR3cq3DzBrWWc+w5aB9mD93et6llFSW0OgSEY9Iuiwi3gR+IKkW+OHGrjwiTtrA8wGctbHraY0u\n2iP52I/nXIeZNWz20C702/NC2j/99bxLKaksu6dWSmoDvCnpa5KOADbuCKtt0Hcvv4jvXn5R3mWY\nWQMk0WW31zh19s2sGTku73JKKkto/DvQlWT4kL2BrwBnFLMog+779KL7Pr3yLsPMGvHhk5szb/bn\nmTDl4LxLKakNhkZEPBsRSyPi7xFxSkQcCcwqfmnV7aWVX+CllV/Iuwwza8ScfxnPxAe34Otxed6l\nlFSToSFpN0lHS+qdzu8g6Rbg2ZJUV8W6zOlClzld8i7DzBpx1AP78ULNZbz+1yF5l1JSTV0R/hPg\nNuBk4E+SLiY5LjsZ+FRJqqtiQwfeztCBt+ddhpk14tW+a+m7+kmW9To371JKqqmzp44CdomI5ZI2\nIxnOY6eImFma0qrbmO7fBqC6TuYzaz0OGfBFlmo5i//xOHBi3uWUTFOhsSIilgNExHuSXndglM7P\nh1yZTvm4hlk5+l238fTq/Xc+terAvEspqaZCY4ikupFsBQwumCcijilqZVVuxn3Dkonj8q3DzBo2\nfK8HuYUvEZ0f4YDque64ydA4tt78NcUsxNa3xbtP5F2CmTXhzLd/zSaT5zN7t/5U0+V9TQ1YOL6U\nhdj6Hjv6QwBOyLkOM2vY6dNuZvDmf2Ta5CPg2Or5Tc0yjIjl4H/e8r0TqoGk/sBACn4XI+Kp/Cqy\nrBb3eILVz/Sgc82f8y6lpBwaZWrQiuR021n5lmFFJOlnJBuT04A16eIAHBqtwA7PD6RTxy8y5MXf\n511KSWUODUkdI2JlMYuxdVYc8rEbFFrlORrY1r9XrVPXNfvwTtvx9Fs1IO9SSmqDw4hI2l3SFOCN\ndH4XSVcXvbIqd1scy21R/1wEqzAzSW8FYK2PNmnD6IFfY02f6rrWOcuWxlXA4cD9ABExWdJni1qV\nsWhR37xLsOL7AJiU3sb4o62NiDg7v5Isq779tuWG9uMZ1b1f3qWUVJbQaBMRs+vd7nNNY42tZbw3\nKT0bwxsblezB9GGt0Ky+E9hnh8d499kv5V1KSWUJjTmSdgdCUlvgm0CpbvdatT63ate8S7Aii4ib\nJXVg3Vhur0XEqjxrsuwe6juMxRN2Y899n6+qU+Oz3E/jTOA8YADwNjAqXWZF9NbyWby1fFbeZVgR\nSdqP5FjhtcB1wOuSPp1rUZbZljNe5rjel/Dn6fvlXUpJZdnSWB0R1TMaV5l4euFEAGo4JedKrIgu\nBw6OiNcAJH0KuAMYmWtVlsluHR/h1x035eJFPwKavHN1RcmypfG8pHGSTpPk27yWyOardmDzVTvk\nXYYVV/u6wACIiNfx2VStRkzcixNrz+OVv3fNu5SS2uCWRkRsLWkvkrF/fyRpEnBnRNxZ9Oqq2K4v\n1w31dVaudVhR1Uq6AfhtOn8yUJtjPdYM6jKSQW1msXjhUXmXUlJZtjSIiP9LTwMcASwhuTmTFdHo\nC9ox+gJfsF/hziS5Gvzs9DENHy9sNQb12JTZO8+lx2Zr8y6lpDb4V0lSN5IbMp0IbA88AOxV5Lqq\n3qjly/MuwYosvRL8ivRhrcx9h7zJXau+yr/2+QPVtK2R5avsVOAh4OcR8XSR67HUo7Ou3HAja5Uk\n/S4iRqcjLUT95yNi5xzKsmZ6ecYw5r9/MDsM+C2/yLuYEsoSGkMiorq2v8rAml4d8y7Biuec9N/D\nc63CNsqE989h+p1b8Hu+A2cckXc5JdNoaEi6PCK+BdwjqaFvQ75zXxGtqumddwlWJBExP51cCCyP\niLXp6bbbAX/MrzJrjlW0Z9kh38u7jJJrakvjrvRf37EvB+sGK3wz1zqsqJ4C9pXUE/gz8DzJUOkn\n51qVZdJ+zGN85bfTAXgp51pKqdGzpyLiuXRy+4gYX/ggOSC+0SQdKuk1STMknd/A86dLWiBpUvr4\nckustzV4+qlTePopX9hX4RQRHwDHANdFxPGAL85pLbYYzvkTfsz5E36cdyUlleWU2zMaWLbRI3Sl\n41hdCxwGDANOkjSsgaZ3RcTw9HHDxq7XrIxI0p4kWxZ/SJe1zbEea6ZlNTuxrGanvMsoqaaOaZxA\ncprtYEn3FjzVHXi/Bda9OzAjImam67uT5NTeaS3w3q3eFms2y7sEK75zgQuA+yLiFUlDgMdzrsma\nYVib2XmXUHJNHdN4DngX2JJki6DOUlpmF15/YE7B/FxgjwbaHZsO4vY68O8RMad+A0ljgDEAAwZU\nxl20RizpmXcJVmQR8STwZMH8TJKL/D5SiX27kkxbOxBIRnGtFo2GRkT8Dfgb8FjpyvmYh4A7ImKl\npK8CNwP7128UEWOBsQA1NTUfO9OrNXryreQ8BA9YWHkk/TIizpX0EA1fp3FkwXTF9e1Kcsald224\nUYVpavfUkxHxGUmLWL9jC4iI2Nj9J/OArQrmt0yXfSQi3i2YvQH4+Uaus9Vo087fKivYrem/l+Va\nhdkn0NTuqbpbuhbrgoHngaGSBpOExYnAFwsbSOpXcE77kcD0ItVSdjzCbeWKiBfSyVrS6zTgo5ND\nfFWnlbWmTrmtuwp8K6BtRKwB9gS+Cmz0WMARsRr4BvAISRj8Lj0YeImkus3zsyW9Imkyyb7e0zd2\nva3Fri9fUzDSrVWo8UCXgvnO5Ls72GyDsgwjcj+wm6Stgf8FHgZupwWGQIiIccC4essuLJi+gOTs\nkqoze0CS2S1yQYyVq04R8c+6mYj4p6QuTb3ALG9ZQmNtRKySdAxwdURcJamaLoDMxaF7vZV3CVZ8\nyySNiIgXASSNBDy8sZW1TLd7lXQ8cApwdLrMdxcrskErbgdgVr5lWHGdC9wt6R8kJ5j0JRlGxKxs\nZQmNM4CvkwyNPjM9cH1Hccsyq3wR8byk7YBt00WvRcSqPGsy25Ast3udKulsYJu0g8+IiP8sfmnV\nbcUh/fMuwYosPX5xHjAwIr4iaaikbSPi4bxrM2vMBseekrQvMAO4EfgN8LqkvYtdWLXbMSazY0zO\nuwwrrv8FPiQ5KxGSU88vza8csw3Lsnvqv4HPRcQ0AEnbk1ycVFPMwqrdBVySTp2Wax1WVFtHxAmS\nTgKIiA8kKe+izJqSZZTbDnWBARAR04EOxSvJrGp8KKkz6YgL6WntK/MtyaxpWbY0XpR0PfDbdP5k\nquueI7lYtKhv3iVY8V0E/AnYStJtwN5U0QWs1jplCY2vkVyN/Z10/mng6qJVZABMnXIQAMcdu4GG\n1iqlu6FeJbkB0yiSU27PiYiFuRZmtgFNhoaknYCtScb7r5rBAsuB76dR2SIiJI2LiJ1YdwMms7LX\n6DENSd8jGULkZOBRSQ3dwc+KZMSSnr6nRuV7UdJueRdh1hxNbWmcDOwcEcsk9SEZI+o3pSnLfD+N\nqrAH8K+SZgHLWHfbgZ1zrcqsCU2FxsqIWAYQEQskZTnTylqI76dRFQ7JuwCz5moqNIYU3BtcwNaF\n9wqPiGOKWlmV69pux7xLsCKR1InkBJNtgCnAjemtAszKXlOhUf+8Hd/coYSu3v9XAIzh6zlXYkVw\nM7CK5EzEw4BhwDm5VmSWUVP3CB9fykJsfaOWe4TsCjYsPWsKSTcCz+Vcj1lmWa7TsBycOm/zvEuw\n4vloJNuIWO2RQ6w1cWiUqS/2+BEAc3Kuw4piF0lL0mkBndP5urOneuRXmlnTMoeGpI4R4XFxSmTb\nkfPyLsGKJCLa5l2D2SeVZWj03SVNAd5I53eR5GFEiuwCLikY6dbMrDxk2dK4Cjic5OpwImKypM8W\ntSrj6aeSi/oO2D/nQszMCmQJjTYRMbvewbo1RarHUl9ecUDeJZiZfUyW0JgjaXcgJLUFvgm8Xtyy\n7K6//QyAb7FvzpWYma2TJTTOJNlFNQB4G3gsXWZF1KnneXmXYGb2MRsMjYh4BzixBLVYgf2fOCud\nmp5rHWZmhTYYGpL+h/R2lIUiYkxRKjIARl+Q/NdMybkOM7NCWXZPPVYw3Qn4Ar7mrOium+Hru8ys\n/GTZPXVX4bykW4FnWmLlkg4FrgTaAjdExE/rPd8RuAUYCbwLnBARs1pi3eXu+P2vBeCtnOswMyv0\nSe6RMRjY6IGR0jOxrmXdKJ8nSRpWr9mXgEURsQ3w38DPNna9rcW2q6az7SofzzCz8pLlmMYi1h3T\naAO8B5zfAuveHZgRETPT9dwJHAVMK2hzFHBxOv174BpJioiPHWOpNJf/Ib29wsH51mFmVqjJ0FBy\nRd8uQN1ASGtb8A92f9Y/NjKX5PaXDbZJRwNdDPQCFtarcwwwBmDAgMq4492br/0E8O1eq10l9m1r\n3ZrcPZUGxLiIWJM+yvIbfkSMjYiaiKjp06dP3uW0iBP+NI0T/jRtww2tolVi37bWLcsxjUmSdi3C\nuucBWxXMb8m6LZqPtZHUDtiE5IC4mZnloNHdU5Lapfct3hV4XtKbwDLWjfk/YiPX/TwwVNJgknA4\nEfhivTYPAqcBE4HjgAnlurVjZlYNmjqm8RwwAjiyGCtOj1F8A3iE5JTb30TEK5IuAWoj4kHgRuBW\nSTNIDsD7ynQzsxw1FRoCiIg3i7XyiBgHjKu37MKC6RXA8cVav5mZNU9TodFHUqOj5kXEFUWox8zM\nylhTodEW6Ea6xWFmZtZUaMyPCN9v1MzMPtLUKbfewjAzs/U0FRq+36iZma2n0dCIiPdKWYiZmZW/\nTzLKrZmZVSmHhpmZZebQMDOzzBwaZmaWmUPDzMwyc2iYmVlmDg0zM8vMoWFmZpk5NMzMLDOHhpmZ\nZebQMDOzzBwaZmaWmUPDzMwyc2iYmVlmDg0zM8vMoWFmZpk5NMzMLDOHhpmZZebQMDOzzBwaZmaW\nmUPDzMwyyyU0JG0m6VFJb6T/9myk3RpJk9LHg6Wu08zM1pfXlsb5wPiIGAqMT+cbsjwihqePI0tX\nnpmZNSSv0DgKuDmdvhk4Oqc6zMysGfIKjc0jYn46/RaweSPtOkmqlfRXSQ4WM7OctSvWG0t6DOjb\nwFPfL5yJiJAUjbzNwIiYJ2kIMEHSlIh4s4F1jQHGAAwYMGAjKzcrH+7bVm6KFhoRcWBjz0l6W1K/\niJgvqR/wTiPvMS/9d6akJ4BdgY+FRkSMBcYC1NTUNBZAZq2O+7aVm7x2Tz0InJZOnwY8UL+BpJ6S\nOqbTvYG9gWklq9DMzD4mr9D4KXCQpDeAA9N5JNVIuiFtsz1QK2ky8Djw04hwaJiZ5ahou6eaEhHv\nAgc0sLwW+HI6/X/ATiUuzczMmuArws3MLDOHhpmZZebQMDOzzBwaZmaWmUPDzMwyc2iYmVlmDg0z\nM8vMoWFmZpk5NMzMLDOHhpmZZebQMDOzzBwaZmaWmUPDzMwyc2iYmVlmDg0zM8vMoWFmZpk5NMzM\nLDOHhpmZZebQMDOzzBwaZmaWmUPDzMwyc2iYmVlmDg0zM8vMoWFmZpk5NMzMLDOHhpmZZebQMDOz\nzBwaZmaWWS6hIel4Sa9IWiuppol2h0p6TdIMSeeXskYzM/u4vLY0pgLHAE811kBSW+Ba4DBgGHCS\npGGlKc/MzBrSLo+VRsR0AElNNdsdmBERM9O2dwJHAdOKXqCZmTUol9DIqD8wp2B+LrBHQw0ljQHG\npLMrJU0tcm2l0htYmHcRLaSSPsu2pVqR+3arUCmfJVO/LlpoSHoM6NvAU9+PiAdacl0RMRYYm663\nNiIaPU7SmvizlCdJtaVal/t2+auUz5K1XxctNCLiwI18i3nAVgXzW6bLzMwsJ+V8yu3zwFBJgyV1\nAE4EHsy5JjOzqpbXKbdfkDQX2BP4g6RH0uVbSBoHEBGrgW8AjwDTgd9FxCsZ3n5skcrOgz9Lecrr\ns/hnWJ4q5bNk+hyKiGIXYmZmFaKcd0+ZmVmZcWiYmVlmFRkaWYcpKWeVMoSKpN9Ieqe1X18gaStJ\nj0ualvatc3Kqo1X3bffr8tPcvl2RoUGGYUrKWYUNoXITcGjeRbSA1cC3ImIYMAo4K6f/k1bbt92v\ny1az+nZFhkZETI+I1/KuYyN8NIRKRHwI1A2h0upExFPAe3nXsbEiYn5EvJhOLyU5o69/DnW05r7t\nfl2Gmtu3KzI0KkBDQ6iU/A+UNUzSIGBX4Nl8K2l13K/LXJa+Xc5jTzWplMOUmNWR1A24Bzg3IpYU\naR3u21ZyWft2qw2NFhimpJx5CJUyJKk9yS/VbRFxb7HWU8F92/26TDWnb3v3VHnyECplRsk4/jcC\n0yPiirzraaXcr8tQc/t2RYZGY8OUtBYbMYRK2ZF0BzAR2FbSXElfyrumT2hv4BRgf0mT0sfnSl1E\na+7b7tdlq1l928OImJlZZhW5pWFmZsXh0DAzs8wcGmZmlplDw8zMMnNomJlZZg6NFiJpTcHpapPS\ny/EbazuoJUbHlPREOmLoZEl/kbTtJ3iPr0k6NZ0+XdIWBc/d0BIDytWr83lJwzO85lxJXTZ23db6\nFfxuTZX0kKRNW/j9T5d0TTp9saRvt+T7VxqHRstZHhHDCx6zSrTekyNiF+Bm4BfNfXFEXB8Rt6Sz\npwNbFDz35YiY1iJVrqvzOrLVeS7g0DBY97u1I8kggWflXVA1c2gUUbpF8bSkF9PHXg202UHSc+k3\nqZclDU2X/2vB8l+nw0o35Slgm/S1B0h6SdKUdNz/junyn6Zj5r8s6bJ02cWSvi3pOKAGuC1dZ+d0\nC6Em3Rr56A99vW9mza1zIgWD1En6laTadBz/H6XLziYJr8clPZ4uO1jSxPTneHc6To5Vn/r95z/S\nrdeX6/pPuvzUdNlkSbemy46Q9Gz6u/GYpM1zqL/Vc2i0nM4Fu6buS5e9AxwUESOAE4CrGnjd14Ar\nI2I4yR/tuZK2T9vvnS5fA5y8gfUfAUyR1IlkrP8TImInkvHFzpTUC/gCsENE7AxcWvjiiPg9UEuy\nRTA8IpYXPH1P+to6JwB3fsI6DwXuL5j/fkTUADsDn5G0c0RcBfwD+GxEfFZSb+AHwIHpz7IWOG8D\n67EKk34hOYB06BFJBwNDSYZcHw6MlPRpSTuQ9Jf9063bupsKPQOMiohdSYZl/06JP0JFaLUDFpah\n5ekfzkLtgWvSffhrgE818LqJwPclbQncGxFvSDoAGAk8LwmgM0kANeQ2ScuBWcA3gW2Bv0XE6+nz\nN5Nszl8DrABulPQw8HDWDxaKt11TAAACeElEQVQRCyTNlDQKeAPYDvhL+r7NqbMD0I3kF7zOaElj\nSPpiP5Kb87xc77Wj0uV/SdfTgeTnZtWhs6RJJFsY04FH0+UHp4+X0vluJCGyC3B3RCwEiIi6+15s\nCdwlqR9JH/pbacqvLA6N4vp34G2STtyG5I/2eiLidknPAp8Hxkn6KiDg5oi4IMM6To6I2roZSZs1\n1CgiVkvaneSb2nEkYwDt34zPcicwGngVuC8iQslf8Mx1Ai+QHM+4GjhG0mDg28BuEbFI0k1ApwZe\nK+DRiDipGfVa5VgeEcPTEyMeIfmychVJv/hJRPy6sLGkbzbyPlcDV0TEg5L2Ay4uXsmVy7unimsT\nYH5ErCUZEOxj+/slDQFmprtkHiDZTTMeOE7Sv6RtNpM0MOM6XwMGSdomnT8FeDI9BrBJRIwjCbNd\nGnjtUqB7I+97H8ld1k4iCRCaW2ckA539EBglaTugB7AMWJzuXz6skVr+Cuxd95kkdZXU0FabVbCI\n+AA4G/iWpHYkAXJG3fEtSf3TvjgBOD7dJVv4RWoT1g3FflpJi68gDo3iug44TdJkkl06yxpoMxqY\nmm5+7wjckp6x9APgz5JeJtkc75dlhRGxAvg34G5JU4C1wPUkf4AfTt/vGRo+JnATcH3dgfB677uI\nZNfAwIh4Ll3W7DrTYyWXA/8REZNJdi28CtxOssurzljgT5Iej4gFJGd23ZGuZyLJz9OqTES8RLL7\n8qSI+DNJv5mY9vXfA93TkXP/k+TL0mSgbrjvi0l+L14AFpa8+ArhUW7NzCwzb2mYmVlmDg0zM8vM\noWFmZpk5NMzMLDOHhpmZZebQMDOzzBwaZmaW2f8DzTu/idBXVAUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y9xkIuR1YNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(my_false_positive_rate, my_true_positive_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPUu73FM4ca_",
        "colab_type": "text"
      },
      "source": [
        "# Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35NQPMvN3TM5",
        "colab_type": "code",
        "outputId": "4921d500-a275-4c3e-a310-5cf6e9253646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(ver_list[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOGZ8Erv415L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "islist = ver_list[0][1]\n",
        "truth = 0\n",
        "false = 0\n",
        "for j in islist:\n",
        "  if j == True:\n",
        "    truth += 1\n",
        "  else:\n",
        "    false += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOgNbLBn5Ftz",
        "colab_type": "code",
        "outputId": "8e01dd63-ca26-41af-e8f7-321fcf243f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "truth, false"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 3000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    }
  ]
}